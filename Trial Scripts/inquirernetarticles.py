# -*- coding: utf-8 -*-
"""InquirerNetArticles.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kLSdf7aKeoIz5TKwfLSZamdbmC4zKChK
"""

from serpapi import GoogleSearch
import csv

API_KEY = ' ### '

def serpapi_search(query, api_key, start=0):
    params = {
        "q": query,
        "location": "Philippines",
        "hl": "tl",  # Language: Tagalog
        "gl": "ph",  # Country: Philippines
        "google_domain": "google.com.ph",
        "start": start,
        "num": 5000,
        "api_key": api_key
    }
    search = GoogleSearch(params)
    return search.get_dict()

def parse_results(search_results):
    data = []
    for result in search_results.get('organic_results', []):
        title = result['title']
        link = result['link']
        snippet = result.get('snippet', 'No snippet available')
        # Append data to the list
        data.append([title, link, snippet])
    return data

def save_to_csv(data, filename='inquirer_articles.csv'):
    with open(filename, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(['Title', 'Link', 'Snippet'])
        writer.writerows(data)

def fetch_all_results(query, api_key):
    all_data = []
    start = 0
    while True:
        results = serpapi_search(query, api_key, start=start)
        data = parse_results(results)
        if not data:
            break
        all_data.extend(data)
        start += 10
    # Save to Google Drive
    file_path = '/content/drive/My Drive/Colab Notebooks/inquirer_articles.csv'
    save_to_csv(all_data, filename=file_path)

query = "site:newsinfo.inquirer.net contraceptive OR condoms OR birth control OR contraception OR ordinance"

fetch_all_results(query, API_KEY)